Bootstrap: library
From: ubuntu:20.04

####
#
# Authors:      Chris Wood, EPCC, University of Edinburgh <c.wood@epcc.ed.ac.uk>; James Harle, National Oceanography Centre <jdha@noc.ac.uk>
# Date:         2019-09-06
# Last updated: 2020-21-04
#
#   Unresolved issues / future work:
#       - significant testing needed - does OpenMPI version on Cirrus need to the same as version in this def file?
#       - do we _need_ to (should we) run all available `make [check|test]` for dependencies?
#       - did I waste a lot of time working out how to compile dependencies from source? (David H suggested that some apt binaries might work, despite my comment below!)
#       - we could change the workflow of all of this by creating individual docker files of all the dependencies (with same base OS image, probably something minimal? alpine?),
#         doing a multistage build, and creating the singularity container from the final resultant docker container. Singularity doensn't (yet) allow multistage builds
#           - however, it's not possible to pull multiple docker images in 1 recipe, so would need to do an incremental build which is probably too much effort for any benefit it would provide  
#       - one of the issues I had running `make check` for hdf5 was with running it as root - mpiexec complains about this. I created the nemo user to run (with the side effect that
#         it created a useful location - the home directory - to store some of the dependencies!). But I then had issues with adding the hdf5 libraries to search paths used by NetCDF, nemo, and xios,
#         so changed --prefix from /home/nemo/hdf5 to /usr/local, but you can't install stuff to there without being root (or sudo, which isn't directly supported in a container). Way round it would be
#         build in /home/nemo as nemo, then install as root, and switch back to nemo user? Is it worth it? But only need to worry about this if we want to run `make check`. Also had similar issues with
#         NCDIR and NFDIR for NetCDF install directories (changed from /home/nemo/netcdf/install to /usr/local). If there's a way round it (and there's a reason to do it), then LD_LIBRARY_PATH and PATH
#         will need to be set and updated
#
#         I also thought it would be useful to keep all the 3rd party dependencies in a separate place, rather than /usr/local, but maybe that's just being a bit OCD...
#       - the nemo-singularity repo is currently private, so need to supply a username/password
#       - I keep the def file in a different repo to the singularity nemo build because it is a different thing - someone running `singularity build` doesn't need the whole singularity-nemo repo (apart from
#         inside the container) 
#
#       - note I currently change branch in the nemo singularity repo rather than use master
####

#%files
#    /home/cwood/.ssh/authorized_keys /root/.ssh/authorized_keys

%post

    ##
    #
    # Compilation from source necessary where apt-get binaries weren't compiled with necessary dependencies for XIOS and NEMO
    #
    ##

    ##
    # install basic stuff
    ##

    apt install -y locales #locales-all
    locale-gen en_GB en_GB.UTF-8 # en_US en_US.UTF-8

    apt install -y software-properties-common
    add-apt-repository universe
    apt update

    # n.b. 
    #   - libcurl4-openssl-dev also installs libcurl4 (as does curl, if not already installed)
    #   - zlib already installed
    apt install -y python wget 

    cd /
    mkdir ugg1

    cd
    echo $PWD
    mkdir ugg

    cd /ugg1
    wget https://download.open-mpi.org/release/open-mpi/v4.1/openmpi-4.1.1.tar.bz2
    mkdir openmpi 
    tar -xvjf openmpi-4.1.1.tar.bz2 -C openmpi --strip-components 1

%environment
    
    # this is needed - nemo is built dynamically (and openmpi, the other library needed, is dealt with in the wrapper script automagically)
    export LD_LIBRARY_PATH=/opt/hdf5/install/lib:$LD_LIBRARY_PATH

%runscript
    #!/bin/bash

    # This runscript will take 2 arguments: program to run (NEMO or XIOS), and an output directory. By default, the output directory will be the job id (passed using $SLURM_JOB_ID).    

    # create directory so we can symlink to /nemo/nemo/cfgs/GYRE_PISCES/EXP00/
    # we should allow an output directory, and manage this in a cleanup section of the batch script, before deleting the symlinked directory there

    # Improvements:
    #   - update when we use a generic cfg directory
    #   - is using $SLURM_JOB_ID directly here best, or should we pass it as the 2nd argument to the script and use a more generic variable here?
    #   - we could make the arguments a bit more intelligent; e.g.
    #       - if only 1 argument, check whether it's nemo or xios; if neither then it's an output directory (and run nemo in attached mode)
    #       - does the output directory need to be set for both 

    if ! [[ $1 == "nemo" || $1 == "xios" ]]    
    then
      echo "The program argument should be either 'nemo' or 'xios'"
      exit 1
    fi

    results_dir=$2

    if [[ -z $2 ]]
    then
      results_dir=$SLURM_JOB_ID
    fi

    if [[ -z $results_dir ]]
    then
        echo "Please supply an output directory"
        exit 1
    fi

    if [[ ! -d $results_dir ]]
    then
        mkdir $results_dir
    fi 

    cd $results_dir

    for file in /nemo/nemo/cfgs/GYRE_PISCES/EXP00/*
    do
    
        # check if the file is already symlinked to prevent lots of spurious error messages
        # but, we have to create this linkfile variable: some of the nemo files are themselves symlinks, so the 
        # if statement will fail to create a symlink for those if we just use the base path
        
        linkfile=`basename $file`

        if ! [[ -L $linkfile ]]
        then
            ln -s $file $linkfile
        fi
    done
    

    if [[ $1 == 'nemo' ]]
    then
        /opt/nemo/nemo
    else
        /opt/xios/xios
    fi

    # do some checking here to make sure the job has finished (to do), and then delete the symlinks:

    #find . -type l | while read linkname
    #do
    #    rm $linkname
    #done

%labels
    Author c.wood@epcc.ed.ac.uk
    Version v0.0.1

%help
    The definition file used to create this container builds NEMO, XIOS, and the following dependencies from source:
        - OpenMPI (4.0.1)
        - HDF5 (1.10.5)
        - NetCDF C (4.7.1) and Fortran (4.5.2) libraries 

    This container includes XIOS v2.5 and a GYRE_PISCES build of NEMO

    To build the container, run

        singularity build nemo.sif nemo.def

    To build, it requires you to have read access to the NOC-MSM `singularity-nemo` repository. If you have SSH access set up, you can pass the SSH_AUTH_SOCK environment variable to 
    prevent being prompted for your username and password, by building as

        sudo SINGULARITYENV_SSH_AUTH_SOCK=$SSH_AUTH_SOCK singularity build nemo.sif nemo.def

    The resulting container has one mandatory and on optional arugments: the program to run with that instance (nemo or xios), and an output directory name. If submitted as part of a slurm 
    sunmission, the output directory name will, by default, be the job id

    # more info about running mpi with examples, e.g.

    # mpirun -npernode 1 -n 1 --mca orte_base_help_aggregate 0 --mca btl_vader_single_copy_mechanim none --mca btl ^sm --mca btl_openib_allow_ib true --bind-to core singularity -d exec -B /etc/libibverbs.d --env LD_LIBRARY_PATH=/opt/hdf5/install/lib:$LD_LIBRARY_PATH --pwd $HOME/containers/nemo/cfgs/GYRE_PISCES/EXP00 nemo.sif /opt/nemo/nemo : -N 1 -n 1 singularity exec --pwd $HOME/containers/nemo/cfgs/GYRE_PISCES/EXP00 nemo.sif /nemo/nemo/cfgs/GYRE_PISCES/EXP00/xios_server.exe 
